{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake-Damage-in-Nepal\n",
    "Starter notebook for the Earthquake-Damage-in-Nepal project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4372599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-sql in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (0.5.0)\n",
      "Requirement already satisfied: prettytable in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython-sql) (3.16.0)\n",
      "Requirement already satisfied: ipython in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython-sql) (9.7.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython-sql) (2.0.44)\n",
      "Requirement already satisfied: sqlparse in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython-sql) (0.5.3)\n",
      "Requirement already satisfied: six in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython-sql) (1.17.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from sqlalchemy>=2.0->ipython-sql) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from sqlalchemy>=2.0->ipython-sql) (4.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.2 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->ipython-sql) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from jedi>=0.18.1->ipython->ipython-sql) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython->ipython-sql) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython->ipython-sql) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython->ipython-sql) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipython-sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719a84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Encoding & Modeling\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20656f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py\", line 143, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "                             ~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py\", line 3301, in raw_connection\n",
      "    return self.pool.connect()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 447, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 1264, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 711, in checkout\n",
      "    rec = pool._do_get()\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/impl.py\", line 177, in _do_get\n",
      "    with util.safe_reraise():\n",
      "         ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py\", line 224, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/impl.py\", line 175, in _do_get\n",
      "    return self._create_connection()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 388, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 673, in __init__\n",
      "    self.__connect()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 899, in __connect\n",
      "    with util.safe_reraise():\n",
      "         ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py\", line 224, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 895, in __connect\n",
      "    self.dbapi_connection = connection = pool._invoke_creator(self)\n",
      "                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/create.py\", line 661, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py\", line 629, in connect\n",
      "    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sql/magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "        connect_str,\n",
      "    ...<2 lines>...\n",
      "        creator=args.creator,\n",
      "    )\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sql/connection.py\", line 70, in set\n",
      "    cls.current = existing or Connection(descriptor, connect_args, creator)\n",
      "                              ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sql/connection.py\", line 55, in __init__\n",
      "    self.internal_connection = engine.connect()\n",
      "                               ~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py\", line 3277, in connect\n",
      "    return self._connection_cls(self)\n",
      "           ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py\", line 145, in __init__\n",
      "    Connection._handle_dbapi_exception_noconnection(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        err, dialect, engine\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py\", line 2440, in _handle_dbapi_exception_noconnection\n",
      "    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py\", line 143, in __init__\n",
      "    self._dbapi_connection = engine.raw_connection()\n",
      "                             ~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/base.py\", line 3301, in raw_connection\n",
      "    return self.pool.connect()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 447, in connect\n",
      "    return _ConnectionFairy._checkout(self)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 1264, in _checkout\n",
      "    fairy = _ConnectionRecord.checkout(pool)\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 711, in checkout\n",
      "    rec = pool._do_get()\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/impl.py\", line 177, in _do_get\n",
      "    with util.safe_reraise():\n",
      "         ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py\", line 224, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/impl.py\", line 175, in _do_get\n",
      "    return self._create_connection()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 388, in _create_connection\n",
      "    return _ConnectionRecord(self)\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 673, in __init__\n",
      "    self.__connect()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 899, in __connect\n",
      "    with util.safe_reraise():\n",
      "         ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/util/langhelpers.py\", line 224, in __exit__\n",
      "    raise exc_value.with_traceback(exc_tb)\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/pool/base.py\", line 895, in __connect\n",
      "    self.dbapi_connection = connection = pool._invoke_creator(self)\n",
      "                                         ~~~~~~~~~~~~~~~~~~~~^^^^^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/create.py\", line 661, in connect\n",
      "    return dialect.connect(*cargs, **cparams)\n",
      "           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sqlalchemy/engine/default.py\", line 629, in connect\n",
      "    return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) unable to open database file\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sql/magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "        connect_str,\n",
      "    ...<2 lines>...\n",
      "        creator=args.creator,\n",
      "    )\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sql/connection.py\", line 82, in set\n",
      "    raise ConnectionError(\n",
      "        \"Environment variable $DATABASE_URL not set, and no connect string given.\"\n",
      "    )\n",
      "sql.connection.ConnectionError: Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql sqlite:///Earthquake-Damage-in-Nepal/data/raw/nepal.sqlite\n",
    "%sql SELECT name FROM sqlite_schema WHERE type='table';\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025b75e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sql/magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "        connect_str,\n",
      "    ...<2 lines>...\n",
      "        creator=args.creator,\n",
      "    )\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sql/connection.py\", line 82, in set\n",
      "    raise ConnectionError(\n",
      "        \"Environment variable $DATABASE_URL not set, and no connect string given.\"\n",
      "    )\n",
      "sql.connection.ConnectionError: Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT(district_id)\n",
    "FROM id_map;\n",
    "\n",
    "%%sql\n",
    "SELECT COUNT(*)\n",
    "FROM id_map\n",
    "WHERE district_id = 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ee5cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sql/magic.py\", line 196, in execute\n",
      "    conn = sql.connection.Connection.set(\n",
      "        connect_str,\n",
      "    ...<2 lines>...\n",
      "        creator=args.creator,\n",
      "    )\n",
      "  File \"/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/sql/connection.py\", line 82, in set\n",
      "    raise ConnectionError(\n",
      "        \"Environment variable $DATABASE_URL not set, and no connect string given.\"\n",
      "    )\n",
      "sql.connection.ConnectionError: Environment variable $DATABASE_URL not set, and no connect string given.\n",
      "\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT DISTINCT(i.building_id) AS b_id,\n",
    "       s.*,\n",
    "       d.damage_grade\n",
    "FROM id_map AS i\n",
    "JOIN building_structure AS s USING (building_id)\n",
    "JOIN building_damage   AS d USING (building_id)\n",
    "WHERE district_id = 3\n",
    "LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b3febf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(db_path):\n",
    "    # open DB connection\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # SQL query to combine relevant tables\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT(i.building_id) AS b_id,\n",
    "               s.*,\n",
    "               d.damage_grade\n",
    "        FROM id_map AS i\n",
    "        JOIN building_structure AS s ON i.building_id = s.building_id\n",
    "        JOIN building_damage   AS d ON i.building_id = d.building_id\n",
    "        WHERE district_id = 3\n",
    "    \"\"\"\n",
    "\n",
    "    # Load into dataframe\n",
    "    df = pd.read_sql(query, conn, index_col=\"b_id\")\n",
    "\n",
    "    # remove potentially leaked features\n",
    "    exclude = [col for col in df.columns if \"post_eq\" in col]\n",
    "\n",
    "    # convert damage grade → numeric → binary class\n",
    "    df[\"damage_grade\"] = df[\"damage_grade\"].str[-1].astype(int)\n",
    "    df[\"severe_damage\"] = (df[\"damage_grade\"] > 3).astype(int)\n",
    "\n",
    "    # additional features removed\n",
    "    exclude += [\"damage_grade\", \"count_floors_pre_eq\", \"building_id\"]\n",
    "\n",
    "    # drop flagged columns\n",
    "    df.drop(columns=exclude, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d65bc41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ayoub.elfilali/Desktop/WQU-DataScienceLab/Earthquake-Damage-in-Nepal/notebooks\n",
      "total 16\n",
      "-rw-r--r--  1 ayoub.elfilali  staff  490 Nov  9 20:01 README.md\n",
      "drwxr-xr-x@ 5 ayoub.elfilali  staff  160 Nov 10 16:52 \u001b[34mdata\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 4 ayoub.elfilali  staff  128 Nov  9 20:02 \u001b[34mnotebooks\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 3 ayoub.elfilali  staff   96 Nov  9 19:58 \u001b[34moutputs\u001b[m\u001b[m\n",
      "-rw-r--r--  1 ayoub.elfilali  staff  108 Nov  9 20:02 requirements.txt\n",
      "drwxr-xr-x@ 3 ayoub.elfilali  staff   96 Nov  9 19:58 \u001b[34msrc\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Show current working directory\n",
    "!pwd\n",
    "\n",
    "# List all files and folders one level up\n",
    "!ls -l ..\n",
    "\n",
    "# Search for the sqlite file anywhere inside your project\n",
    "!find .. -name \"*.sqlite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33e84aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"/full/path/from/find/output/nepal.sqlite\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d7bbcc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/raw/id_map.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Step 1: Load CSVs into Pandas\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m id_map = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/raw/id_map.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m structure = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../data/raw/building_structure.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m damage = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../data/raw/building_damage.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/WQU-DataScienceLab/.venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/raw/id_map.csv'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load CSVs into Pandas\n",
    "id_map = pd.read_csv(\"../data/raw/id_map.csv\")\n",
    "structure = pd.read_csv(\"../data/raw/building_structure.csv\")\n",
    "damage = pd.read_csv(\"../data/raw/building_damage.csv\")\n",
    "\n",
    "# Step 2: Create a temporary SQLite database in memory\n",
    "conn = sqlite3.connect(\":memory:\")  # \":memory:\" means it’s temporary\n",
    "\n",
    "# Step 3: Save the CSVs as tables in SQLite\n",
    "id_map.to_sql(\"id_map\", conn, index=False, if_exists=\"replace\")\n",
    "structure.to_sql(\"building_structure\", conn, index=False, if_exists=\"replace\")\n",
    "damage.to_sql(\"building_damage\", conn, index=False, if_exists=\"replace\")\n",
    "\n",
    "# Step 4: Example SQL query — list tables\n",
    "tables = pd.read_sql(\"SELECT name FROM sqlite_schema WHERE type='table';\", conn)\n",
    "print(\"Tables in SQLite DB:\")\n",
    "print(tables)\n",
    "\n",
    "# Step 5: Example SQL query — joi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dd0ff39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33msevere_damage\u001b[39m\u001b[33m\"\u001b[39m].value_counts(normalize=\u001b[38;5;28;01mTrue\u001b[39;00m).plot(\n\u001b[32m      2\u001b[39m     kind=\u001b[33m\"\u001b[39m\u001b[33mbar\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     xlabel=\u001b[33m\"\u001b[39m\u001b[33mSevere Damage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     ylabel=\u001b[33m\"\u001b[39m\u001b[33mProbability\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mDamage Class Proportion\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"severe_damage\"].value_counts(normalize=True).plot(\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Severe Damage\",\n",
    "    ylabel=\"Probability\",\n",
    "    title=\"Damage Class Proportion\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5975ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "roof_effect = pd.pivot_table(\n",
    "    df,\n",
    "    index=\"roof_type\",\n",
    "    values=\"severe_damage\",\n",
    "    aggfunc=np.mean\n",
    ").sort_values(\"severe_damage\")\n",
    "roof_effect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"severe_damage\")\n",
    "y = df[\"severe_damage\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ebd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = y_train.value_counts(normalize=True).max()\n",
    "print(f\"Baseline Acc: {baseline:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = make_pipeline(\n",
    "    OneHotEncoder(use_cat_names=True),\n",
    "    LogisticRegression(max_iter=2000)\n",
    ")\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"LR Train:\", model_lr.score(X_train, y_train))\n",
    "print(\"LR Valid:\", model_lr.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(1, 16)\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "\n",
    "for d in depths:\n",
    "    model_dt = make_pipeline(\n",
    "        OrdinalEncoder(),\n",
    "        DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    )\n",
    "    model_dt.fit(X_train, y_train)\n",
    "    train_scores.append(model_dt.score(X_train, y_train))\n",
    "    valid_scores.append(model_dt.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea695e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(depths, train_scores, label=\"Train\")\n",
    "plt.plot(depths, valid_scores, label=\"Validation\")\n",
    "plt.xlabel(\"Tree Max Depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Decision Tree Validation Curve\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3708b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    ")\n",
    "\n",
    "final_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f26b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"filePath.csv\", index_col=\"b_id\")\n",
    "pred = pd.Series(final_model.predict(X_test))\n",
    "pred.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b997ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = model_lr.named_steps[\"onehotencoder\"].get_feature_names()\n",
    "weights = model_lr.named_steps[\"logisticregression\"].coef_[0]\n",
    "importance = pd.Series(np.exp(weights), index=names).sort_values()\n",
    "\n",
    "importance.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa125390",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.plot(kind=\"barh\")\n",
    "plt.xlabel(\"Relative Influence\")\n",
    "plt.title(\"Logistic Regression Feature Importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3469502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "damage_by_loc = (\n",
    "    df.groupby(\"vdcmun_id\")[\"severe_damage\"]\n",
    "      .mean()\n",
    "      .sort_values(ascending=False)\n",
    ").to_frame()\n",
    "\n",
    "damage_by_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13000c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(damage_by_loc.values)\n",
    "plt.xticks(range(len(damage_by_loc)), damage_by_loc.index, rotation=90)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2))\n",
    "plt.xlabel(\"Municipality\")\n",
    "plt.ylabel(\"Proportion Damaged\")\n",
    "plt.title(\"Damage Rates by Municipality\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
